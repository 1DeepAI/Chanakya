{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f73f442-61ea-438c-953b-bd7d268f892e",
   "metadata": {},
   "source": [
    "# Python Practice 491-500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489cf9f-25f8-4d83-b6dc-6993df510bd9",
   "metadata": {},
   "source": [
    "## Here are Python Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2435cd-cfa7-4024-a8cb-def5bd80db4e",
   "metadata": {},
   "source": [
    "### 491.Implement a Genetic Algorithm with Multi-Objective Tournament Selection and Custom Niching Strategy\n",
    "The following is a basic example of a genetic algorithm with multi-objective tournament selection and a custom niching strategy using the DEAP library:\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "Define the custom fitness assignment.\n",
    "Initialize the population.\n",
    "Define the genetic operations (selection, crossover, mutation).\n",
    "Define the multi-objective tournament selection.\n",
    "Define the custom niching strategy.\n",
    "Evolve the population through generations, selecting individuals based on multi-objective fitness.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "The expected output of the provided code will be the Pareto Front of individuals after running the genetic algorithm for 100 generations. The Pareto Front represents the set of non-dominated solutions, meaning that no other solution in the set is better in all objectives.\n",
    "\n",
    "For the provided code with two objectives: maximizing the sum of values and minimizing the number of negative values, a sample output could be:\n",
    "\n",
    "Pareto Front:\n",
    "(5.724353458359271, 2)\n",
    "(6.421388839895178, 3)\n",
    "(4.002939208384392, 1)\n",
    "(7.359392898485639, 4)\n",
    "...\n",
    "\n",
    "Each line represents an individual's objectives from the Pareto Front. The first value in the tuple is the sum of the individual's values (which we aim to maximize) and the second value is the number of negative values in the individual (which we aim to minimize).\n",
    "\n",
    "Note: The exact values in the output will vary each time the code is run because of the stochastic nature of the genetic algorithm and the random initialization of individuals.\n",
    "\n",
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fde21-7571-4914-a98c-57b471be2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools\n",
    "\n",
    "# Define objectives and fitness\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_float\", random.uniform, -1, 1)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 10)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(individual):\n",
    "    # Objective 1: Sum of values\n",
    "    obj1 = sum(individual)\n",
    "    # Objective 2: Number of negative values\n",
    "    obj2 = sum(1 for x in individual if x < 0)\n",
    "    return obj1, obj2\n",
    "\n",
    "# Genetic operators\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# Custom niching strategy\n",
    "def niching(population, k, tournsize, fit_attr=\"fitness\"):\n",
    "    chosen = []\n",
    "    while len(chosen) < k:\n",
    "        # Select individuals using tournament selection\n",
    "        aspirants = [random.choice(population) for _ in range(tournsize)]\n",
    "        # Custom niching: Prioritize least represented individuals\n",
    "        counts = {}\n",
    "        for ind in aspirants:\n",
    "            if ind.fitness in counts:\n",
    "                counts[ind.fitness] += 1\n",
    "            else:\n",
    "                counts[ind.fitness] = 1\n",
    "        aspirants.sort(key=lambda x: counts[x.fitness])\n",
    "        chosen.append(aspirants[0])\n",
    "    return chosen\n",
    "\n",
    "# Main genetic algorithm\n",
    "def main():\n",
    "    pop = toolbox.population(n=100)\n",
    "    \n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    for gen in range(100):\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(offspring)\n",
    "        \n",
    "        # Clone the selected individuals\n",
    "        offspring = list(toolbox.clone(ind) for ind in offspring)\n",
    "        \n",
    "        # Apply crossover and mutation\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.5:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        \n",
    "        # Evaluate the individuals with invalid fitness\n",
    "        invalids = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalids)\n",
    "        for ind, fit in zip(invalids, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        # Use custom niching\n",
    "        pop[:] = niching(pop + offspring, len(pop), 3)\n",
    "    \n",
    "    return tools.sortNondominated(pop, len(pop), first_front_only=True)[0]\n",
    "\n",
    "pareto_front = main()\n",
    "\n",
    "# Expected output\n",
    "print(\"Pareto Front:\")\n",
    "for individual in pareto_front:\n",
    "    print(individual.fitness.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02abab0-3bea-4a7f-b972-1be3c3b2b033",
   "metadata": {},
   "source": [
    "### 492. Build a Multi-Objective Optimization Algorithm with Multi-Objective Genetic Programming and Custom Fitness Assignment\n",
    "Creating a multi-objective optimization algorithm using multi-objective genetic programming (MOGP) is quite extensive. I'll provide a basic outline and example using DEAP (Distributed Evolutionary Algorithms in Python), a popular library for evolutionary algorithms.\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Define the custom fitness assignment and objectives.\n",
    "2. Initialize the population.\n",
    "3. Define the genetic operations (selection, crossover, mutation).\n",
    "4. Evolve the population through generations, selecting individuals based on multi-objective fitness.\n",
    "5. Return the Pareto front of solutions.\n",
    "\n",
    "NOTE : pip install deap\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "The Pareto front consisting of individuals that represent a trade-off between the two objectives will be printed. Remember, we've defined two dummy objectives for demonstration purposes: one is to maximize the sum of the function values in the range [-10, 10], and the other is to minimize the length of the individual (program).\n",
    "\n",
    "This is a very basic example of Multi-Objective Genetic Programming (MOGP) using DEAP, and the objectives and representation can be tailored further as per specific needs. The DEAP library offers rich flexibility for customization.\n",
    "\n",
    "Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0b6eb-6fa6-4700-b8d7-62cbb1c6822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools, gp\n",
    "import operator\n",
    "\n",
    "# Define objectives and fitness\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))  # Maximizing objective 1, minimizing objective 2\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMulti)\n",
    "\n",
    "# Define functions for our custom program trees\n",
    "def protectedDiv(left, right):\n",
    "    try:\n",
    "        return left / right\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "\n",
    "pset = gp.PrimitiveSet(\"MAIN\", arity=1)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(protectedDiv, 2)\n",
    "pset.addPrimitive(operator.neg, 1)\n",
    "pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-10,10))\n",
    "\n",
    "# Objective functions\n",
    "def objective1(individual):\n",
    "    # Convert tree expression to callable function\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    # In this case, we'll just feed the function numbers from -10 to 10\n",
    "    return sum(func(x) for x in range(-10, 11)),\n",
    "\n",
    "def objective2(individual):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    # Second objective is to keep the expression short\n",
    "    return len(individual),\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", lambda ind: (objective1(ind)[0], objective2(ind)[0]))\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "# Define the main evolution function\n",
    "def main():\n",
    "    random.seed(42)\n",
    "\n",
    "    pop = toolbox.population(n=300)\n",
    "    hof = tools.ParetoFront()\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", tools.mean)\n",
    "    stats.register(\"std\", tools.std)\n",
    "    stats.register(\"min\", min)\n",
    "    stats.register(\"max\", max)\n",
    "    \n",
    "    algorithms.eaMuPlusLambda(pop, toolbox, mu=300, lambda_=600, cxpb=0.5, mutpb=0.2, ngen=50, \n",
    "                              stats=stats, halloffame=hof)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "pop, stats, hof = main()\n",
    "print(hof)  # This will print the Pareto front\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834f3c2-ac77-4537-b657-d8635a50a74f",
   "metadata": {},
   "source": [
    "### 493.Implement a Neural Architecture Search (NAS) Algorithm with One-Shot Architecture Search and Custom Search Space\n",
    "Neural Architecture Search (NAS) aims to find the optimal neural network architecture for a given task. One-shot architecture search is a strategy in which a supernet (a large network that encompasses many sub-networks) is trained, and architectures are then sampled and evaluated without further training.\n",
    "\n",
    "Implementing a full One-shot NAS system in this space is challenging due to its complexity, but I will provide a simplified example using TensorFlow and Keras to give you an idea.\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Define the custom search space.\n",
    "2. Build a supernet that covers the entire search space.\n",
    "3. Train the supernet.\n",
    "4. Sample and evaluate sub-networks from the trained supernet.\n",
    "\n",
    "\n",
    "Expected Output:\n",
    "The code will first train a \"supernet\" on the CIFAR-10 dataset, then it will sample three architectures from the search space, evaluate them on the test set, and print their performances.\n",
    "\n",
    "Note:\n",
    "\n",
    "One-shot NAS usually requires further strategies to share weights and deal with the discrepancies between architectures, often involving auxiliary heads and other tricks to stabilize training. This example simplifies these aspects to fit the format.\n",
    "This example uses the CIFAR-10 dataset and a simple convolutional model for brevity. Adjustments might be necessary for other datasets/tasks.\n",
    "To execute the program, ensure that you have tensorflow installed and that your hardware can handle the training process.\n",
    "\n",
    "Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4d58c-ed5a-461b-966c-53896b3bbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, datasets\n",
    "\n",
    "# Load data\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define custom search space (simplified for this example)\n",
    "search_space = {\n",
    "    'num_blocks': [1, 2, 3],\n",
    "    'num_neurons': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Build the supernet\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "# We're using a max search space approach for simplicity\n",
    "x = inputs\n",
    "for _ in range(max(search_space['num_blocks'])):\n",
    "    for neurons in search_space['num_neurons']:\n",
    "        x = layers.Conv2D(neurons, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the supernet\n",
    "model.fit(train_images, train_labels, epochs=1, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Sample and evaluate sub-networks\n",
    "for _ in range(3):  # evaluate 3 random architectures\n",
    "    num_blocks = np.random.choice(search_space['num_blocks'])\n",
    "    neurons_per_block = np.random.choice(search_space['num_neurons'], size=num_blocks)\n",
    "\n",
    "    # Build the sampled model\n",
    "    x = inputs\n",
    "    for neurons in neurons_per_block:\n",
    "        x = layers.Conv2D(neurons, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "\n",
    "    sampled_model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    sampled_model.set_weights(model.get_weights())  # Transfer weights from the supernet\n",
    "    \n",
    "    loss, acc = sampled_model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Architecture {neurons_per_block} - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc98aa0-1cbd-4052-80c3-fab8eebccf74",
   "metadata": {},
   "source": [
    "### 494. Create a Reinforcement Learning Agent using Proximal Policy Optimization (PPO) with Custom Learning Rate and Policy Clipping\n",
    "Proximal Policy Optimization (PPO) is an advanced reinforcement learning algorithm that balances between exploitation and exploration in policy optimization, outperforming other methods like TRPO in terms of sample efficiency and simplicity.\n",
    "\n",
    "Below is a basic implementation of PPO for the OpenAI gym's CartPole environment:\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Define the actor (policy) and critic (value) networks.\n",
    "2. Define the PPO loss considering custom policy clipping.\n",
    "3. Train the agent in the environment using PPO.\n",
    "4. Render a trained agent in the environment.\n",
    "\n",
    "Expected Output:\n",
    "The agent will train on the CartPole environment and attempt to balance the pole for as long as possible. After the training loop, you'll see a visual representation of the trained agent's performance in the environment.\n",
    "\n",
    "Note:\n",
    "\n",
    "Ensure you have the necessary packages installed (tensorflow, gym, etc.).\n",
    "This is a basic PPO implementation for illustrative purposes. Depending on the environment and task, hyperparameters and architecture may need adjustments.\n",
    "For larger and more complex environments, more sophisticated network architectures, normalization techniques, and hyperparameter tunings will be required.\n",
    "\n",
    "Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c63aff-6a07-4729-83b1-d7d2709a3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "# Hyperparameters\n",
    "GAMMA = 0.99\n",
    "CLIP_RATIO = 0.2  # Policy clipping parameter\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0003\n",
    "\n",
    "# Create CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Actor & Critic Networks\n",
    "inputs = tf.keras.layers.Input(shape=(state_dim,))\n",
    "advantage = tf.keras.layers.Input(shape=(1,))\n",
    "action = tf.keras.layers.Input(shape=(n_actions,))\n",
    "old_prediction = tf.keras.layers.Input(shape=(n_actions,))\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "policy = tf.keras.layers.Dense(n_actions, activation='softmax')(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "value = tf.keras.layers.Dense(1, activation=None)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=[policy, value])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=[ppo_loss(old_prediction, action, advantage, CLIP_RATIO), 'mse'])\n",
    "\n",
    "# Define PPO Loss\n",
    "def ppo_loss(old_policy, action, advantage, clip_ratio):\n",
    "    def loss(y_true, y_pred):\n",
    "        prob = y_pred * action\n",
    "        old_prob = old_policy * action\n",
    "        r = prob / (old_prob + 1e-10)\n",
    "        return -tf.keras.backend.mean(tf.keras.backend.minimum(r * advantage, \n",
    "                                  tf.keras.backend.clip(r, min_value=1 - clip_ratio, \n",
    "                                                        max_value=1 + clip_ratio) * advantage))\n",
    "    return loss\n",
    "\n",
    "def get_action(state):\n",
    "    state = state[np.newaxis, :]\n",
    "    prob, _ = model.predict(state)\n",
    "    action = np.random.choice(n_actions, p=np.nan_to_num(prob[0]))\n",
    "    action_matrix = np.zeros(n_actions)\n",
    "    action_matrix[action] = 1\n",
    "    return action_matrix\n",
    "\n",
    "def get_advantages(values, rewards):\n",
    "    returns = []\n",
    "    gae = 0\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        delta = rewards[i] + GAMMA * values[i + 1] - values[i]\n",
    "        gae = delta + GAMMA * gae\n",
    "        returns.insert(0, gae)\n",
    "    return np.array(returns) - values[:-1]\n",
    "\n",
    "# Training Loop\n",
    "for _ in range(EPOCHS):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    rewards = []\n",
    "    states = []\n",
    "    actions = []\n",
    "    while not done:\n",
    "        action_matrix = get_action(state)\n",
    "        next_state, reward, done, _ = env.step(np.argmax(action_matrix))\n",
    "        states.append(state)\n",
    "        rewards.append((reward + 8) / 8)\n",
    "        actions.append(action_matrix)\n",
    "        state = next_state\n",
    "\n",
    "    _, values = model.predict(np.vstack(states))\n",
    "    values = np.append(values, 0)\n",
    "    advantages = get_advantages(values, rewards)\n",
    "\n",
    "    model.train_on_batch(np.vstack(states), [np.vstack(actions), rewards, advantages])\n",
    "\n",
    "# Display the trained agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = get_action(state)\n",
    "    next_state, _, done, _ = env.step(np.argmax(action))\n",
    "    state = next_state\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1f982-1693-4c97-b243-764edc8da66d",
   "metadata": {},
   "source": [
    "### 495. Develop a Generative Adversarial Network (GAN) with Wasserstein Loss and Gradient Penalty for Image Generation\n",
    "\n",
    "a basic implementation of a Wasserstein GAN with Gradient Penalty (WGAN-GP) using TensorFlow and Keras. This implementation focuses on a simple architecture to generate 28x28 grayscale images (like the ones from the MNIST dataset).\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Define the generator and discriminator networks.\n",
    "2. Define the Wasserstein loss.\n",
    "3. Implement the gradient penalty.\n",
    "4. Compile and train the model.\n",
    "5. Generate images.\n",
    "\n",
    "Expected Output:\n",
    "When you run the code, during training, you'll see the losses (for discriminator and generator) being printed for each epoch. Every 1000 epochs, the sample_images function will generate images which you can save or plot.\n",
    "\n",
    "Note:\n",
    "\n",
    "1. This code is a simple and illustrative example of WGAN-GP. It might require adjustments, especially in the neural network architectures, for more complex datasets or tasks.\n",
    "2. Training GANs, especially WGAN-GP, is computationally intensive. Ensure you have a suitable environment (preferably with a GPU) and sufficient time for training.\n",
    "3. Make sure you have the required packages installed, i.e., TensorFlow.\n",
    "4. To actually view the generated images, you might need to extend the sample_images function to save the images to disk or display them.\n",
    "\n",
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28819ae2-6a8f-4103-a11c-27270643b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, BatchNormalization, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "(train_images, train_labels), (_, _) = mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "# Define the generator\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(128, activation=\"relu\", input_dim=100),\n",
    "        BatchNormalization(),\n",
    "        Dense(784, activation=\"tanh\"),\n",
    "        Reshape((28, 28, 1))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        Flatten(input_shape=(28, 28, 1)),\n",
    "        Dense(128, activation=LeakyReLU(0.2)),\n",
    "        Dense(1)  # No sigmoid activation, because of Wasserstein loss\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "# Gradient penalty\n",
    "def gradient_penalty(batch_size, real_images, fake_images, discriminator):\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        predictions = discriminator(interpolated_images)\n",
    "    gradients = tape.gradient(predictions, interpolated_images)\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "discriminator.compile(loss=wasserstein_loss, optimizer=discriminator_optimizer)\n",
    "\n",
    "# Build and compile the combined model\n",
    "generator = build_generator()\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(img)\n",
    "combined = Model(z, validity)\n",
    "combined_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "combined.compile(loss=wasserstein_loss, optimizer=combined_optimizer)\n",
    "\n",
    "# Train WGAN-GP\n",
    "def train(epochs, batch_size=128, sample_interval=50):\n",
    "    real_labels = -np.ones((batch_size, 1))\n",
    "    fake_labels = np.ones((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(5):  # Train discriminator more than generator\n",
    "            idx = np.random.randint(0, train_images.shape[0], batch_size)\n",
    "            real_images = train_images[idx]\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            fake_images = generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "            gp_loss = gradient_penalty(batch_size, real_images, fake_images, discriminator)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) + 10.0 * gp_loss\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            g_loss = combined.train_on_batch(noise, real_labels)\n",
    "        \n",
    "        print(f\"{epoch}/{epochs} [D loss: {d_loss}] [G loss: {g_loss}]\")\n",
    "        \n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch)\n",
    "\n",
    "def sample_images(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "    # Save generated images or plot them here\n",
    "\n",
    "train(epochs=10000, batch_size=32, sample_interval=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0880df-72c7-4dde-a608-26a42ab7db77",
   "metadata": {},
   "source": [
    "### 496. Implement a Transfer Learning Model with Meta-Learning and Custom Metric Learning Loss\n",
    "Implementing a Transfer Learning model with Meta-learning using a custom metric learning loss is quite advanced and usually requires a fair bit of setup and data preprocessing. However, I'll try to give a simplified overview of the idea and a basic structure using TensorFlow.\n",
    "\n",
    "In Meta-learning, models are trained to quickly adapt to new tasks with minimal data. A popular meta-learning approach is Model-Agnostic Meta-Learning (MAML). For simplicity, I'll use the MAML approach and combine it with a custom metric learning loss, such as triplet loss.\n",
    "\n",
    "Step-by-Step Outline:\n",
    "1. Use a pre-trained model (or initialize a new one).\n",
    "2. Implement the MAML update step.\n",
    "3. Define a custom metric learning loss (triplet loss in this case).\n",
    "4. Fine-tune the model on target tasks using the custom loss.\n",
    "5. Evaluate the model's performance.\n",
    "\n",
    "Expected Output:\n",
    "After you train the model using model.fit(), you should see logs indicating the training loss, triplet loss, and accuracy for each epoch. Following the training, when evaluating using model.evaluate(), you'd get the validation accuracy (and any other metrics you've added).\n",
    "\n",
    "Note:\n",
    "1. This is a very simplified implementation. In a real-world setting, more sophisticated techniques like task sampling, gradient clipping, and more might be required.\n",
    "2. You'd also need a specialized data generator for the triplet loss, which provides anchor, positive, and negative samples.\n",
    "3. You might need to adjust hyperparameters, layer configurations, or other aspects to fit your specific needs and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c374381-0948-4f15-b6d4-84e3d24e7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load a pre-trained model or define a new one\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)  # Assuming 10 classes\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Define the MAML update step\n",
    "def maml_update(model, loss, alpha=0.001):\n",
    "    grads = tf.gradients(loss, model.trainable_variables)\n",
    "    k = 0\n",
    "    updated_model = model\n",
    "    for layer in updated_model.layers:\n",
    "        if layer.trainable:\n",
    "            layer.kernel = layer.kernel - alpha * grads[k]\n",
    "            k += 1\n",
    "    return updated_model\n",
    "\n",
    "# Define custom metric learning loss: Triplet Loss\n",
    "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
    "    anchor, positive, negative = tf.split(y_pred, num_or_size_splits=3, axis=0)\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    return loss\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=triplet_loss, metrics=['accuracy'])\n",
    "\n",
    "# Training: Use your own data generator or dataset here\n",
    "# model.fit(dataset, epochs=10)\n",
    "\n",
    "# Evaluation: Use your own evaluation data\n",
    "# evaluation = model.evaluate(validation_data)\n",
    "# print(f'Validation Accuracy: {evaluation[1] * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0009bc5-d765-44d9-876f-138ac743a298",
   "metadata": {},
   "source": [
    "### 497. Develop a Reinforcement Learning Agent using Randomized Prioritized Trust Region Policy Optimization (RP-TRPO) with Custom Exploration Strategy\n",
    "\n",
    "Creating a full-fledged RL agent using Randomized Prioritized Trust Region Policy Optimization (RP-TRPO) with a custom exploration strategy is a complex task and can't be covered in a short space. However, I can provide a high-level outline and a basic skeleton code for the task. For a full implementation, you may need to extend the provided code and possibly utilize deep reinforcement learning frameworks like TensorFlow, PyTorch, or libraries like Stable Baselines.\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "Implement the TRPO algorithm.\n",
    "Prioritize updates based on a combination of TD-error and the magnitude of policy change.\n",
    "Add a randomized exploration strategy.\n",
    "Train the agent and evaluate its performance.\n",
    "\n",
    "Expected Output:\n",
    "The code will train the RP-TRPO agent in a dummy environment. After the training, it will print \"Training completed!\". You may also add any evaluation metrics like average episode reward or length to further evaluate your agent's performance.\n",
    "\n",
    "Remember, this is a skeleton code, and a full-fledged implementation would require more components like a neural network policy, the trust region optimization algorithm, and more sophisticated trajectory storage and retrieval methods.\n",
    "\n",
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e493a38-533f-4588-8804-395055b38ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class RPTROAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        # Define the policy network, value network, and other necessary components here\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Implement your action selection method here. \n",
    "        # Add custom exploration strategy as needed.\n",
    "        pass\n",
    "\n",
    "    def update(self, trajectories):\n",
    "        # Compute the TD-error and magnitude of policy change\n",
    "        # Rank trajectories based on this combined score\n",
    "        # Update the policy using TRPO on a subset of prioritized trajectories\n",
    "        pass\n",
    "\n",
    "# Simulated environment\n",
    "class DummyEnv:\n",
    "    def reset(self):\n",
    "        return np.random.rand(4)\n",
    "    \n",
    "    def step(self, action):\n",
    "        next_state = np.random.rand(4)\n",
    "        reward = -np.sum(np.square(action))\n",
    "        done = False\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "# Main Training Loop\n",
    "if __name__ == \"__main__\":\n",
    "    env = DummyEnv()\n",
    "    agent = RPTROAgent(4, 2)\n",
    "    \n",
    "    for episode in range(1000):\n",
    "        state = env.reset()\n",
    "        trajectories = []\n",
    "        for _ in range(100):\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            trajectories.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        agent.update(trajectories)\n",
    "        # Also add any logging, evaluation, and saving functionalities\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dac1a0-6a6b-4976-a764-25dade08710e",
   "metadata": {},
   "source": [
    "### 498. Implement a Transfer Learning Model with Unsupervised Domain Adaptation and Custom Adversarial Loss\n",
    "\n",
    "Let's implement a transfer learning model with unsupervised domain adaptation using adversarial training. The idea is to learn domain-invariant features such that the model, which is trained on the source domain, can perform well on the target domain without having access to the target domain labels during training.\n",
    "\n",
    "We'll use two datasets: a source dataset (with labels) and a target dataset (without labels). The model will be trained using a combination of classification loss (on source domain) and adversarial loss (on both source and target domains).\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Create synthetic datasets for the source and target domain.\n",
    "2. Build a feature extractor, domain classifier, and label classifier.\n",
    "3. Define the custom adversarial loss.\n",
    "4. Train the model using unsupervised domain adaptation.\n",
    "5. Evaluate the performance on the target domain.\n",
    "\n",
    "\n",
    "Expected Output:\n",
    "The program will generate synthetic datasets, train the model using unsupervised domain adaptation, and finally, evaluate the model's performance on the target domain. The output will be along the lines of:\n",
    "\n",
    "Accuracy on target domain (label prediction): xx.xx%\n",
    "\n",
    "Where xx.xx will be the accuracy of the model's label prediction on the target test set. Note that due to the randomness of the data generation and training process, the exact accuracy may vary between runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3beac8-05e7-48f9-8fe6-a6d413179e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic datasets\n",
    "X_source, y_source = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_target, _ = make_classification(n_samples=1000, n_features=20, random_state=24)\n",
    "\n",
    "# Split the datasets\n",
    "X_source_train, X_source_test, y_source_train, y_source_test = train_test_split(X_source, y_source, test_size=0.2)\n",
    "X_target_train, X_target_test = train_test_split(X_target, test_size=0.2)\n",
    "\n",
    "# Feature extractor\n",
    "feature_extractor = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(20,))\n",
    "])\n",
    "\n",
    "# Label classifier\n",
    "label_classifier = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Domain classifier\n",
    "domain_classifier = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Combined model\n",
    "input_data = keras.Input(shape=(20,))\n",
    "features = feature_extractor(input_data)\n",
    "labels = label_classifier(features)\n",
    "domains = domain_classifier(features)\n",
    "combined_model = keras.Model(inputs=input_data, outputs=[labels, domains])\n",
    "\n",
    "# Custom adversarial loss\n",
    "def custom_adversarial_loss(y_true, y_pred):\n",
    "    return keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "combined_model.compile(optimizer='adam',\n",
    "                       loss=['binary_crossentropy', custom_adversarial_loss],\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Create domain labels for source and target datasets\n",
    "source_domain_labels = np.zeros((X_source_train.shape[0], 1))\n",
    "target_domain_labels = np.ones((X_target_train.shape[0], 1))\n",
    "\n",
    "# Train the model\n",
    "combined_model.fit(X_source_train, [y_source_train, source_domain_labels], epochs=20, verbose=0)\n",
    "combined_model.fit(X_target_train, [np.zeros_like(X_target_train[:, 0]), target_domain_labels], epochs=20, verbose=0)\n",
    "\n",
    "# Evaluate the model on the target domain\n",
    "_, label_acc, domain_acc = combined_model.evaluate(X_target_test, [np.zeros_like(X_target_test[:, 0]), np.ones((X_target_test.shape[0], 1))], verbose=0)\n",
    "print(f\"Accuracy on target domain (label prediction): {label_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292f6c1-a8ab-4a88-b1b0-b950f64a385b",
   "metadata": {},
   "source": [
    "### 499. Build a Transfer Learning Model with Cross-Domain Knowledge Distillation and Custom Teacher Model\n",
    "\n",
    "In this example, we'll build a simple transfer learning model using cross-domain knowledge distillation. The idea is to have a pre-trained \"teacher\" model that will guide a \"student\" model during training. The student model will try to mimic the teacher's behavior, not just match the ground truth labels.\n",
    "\n",
    "Step-by-Step Outline:\n",
    "\n",
    "1. Create a synthetic dataset for the source and target domain.\n",
    "2. Build a teacher model and train it on the source domain data.\n",
    "3. Create a student model.\n",
    "4. Train the student model on the target domain data while using the teacher model's predictions as additional guidance.\n",
    "5. Evaluate the student model's performance.\n",
    "\n",
    "Expected Output:\n",
    "The program will generate synthetic datasets, train the teacher model on the source domain, distill knowledge to the student model on the target domain, and finally, evaluate the student model's performance. The output will be along the lines of:\n",
    "\n",
    "Student model accuracy on target domain: xx.xx%\n",
    "\n",
    "Where xx.xx will be the accuracy of the student model on the target test set. Note that due to the randomness of the data generation and training process, the exact accuracy may vary between runs.\n",
    "\n",
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65904f-ce0d-4868-906f-56b6306134bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic datasets for source and target domains\n",
    "X_source, y_source = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_target, y_target = make_classification(n_samples=1000, n_features=20, random_state=24)\n",
    "\n",
    "# Split the datasets\n",
    "X_source_train, X_source_test, y_source_train, y_source_test = train_test_split(X_source, y_source, test_size=0.2)\n",
    "X_target_train, X_target_test, y_target_train, y_target_test = train_test_split(X_target, y_target, test_size=0.2)\n",
    "\n",
    "# Teacher model\n",
    "teacher_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_source.shape[1],)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "teacher_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "teacher_model.fit(X_source_train, y_source_train, epochs=20, validation_data=(X_source_test, y_source_test), verbose=0)\n",
    "\n",
    "# Student model\n",
    "student_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_target.shape[1],)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Using teacher's predictions as soft labels\n",
    "soft_labels = teacher_model.predict(X_target_train)\n",
    "\n",
    "# Custom loss: Combine soft labels from teacher and true labels\n",
    "def distillation_loss(y_true, y_pred, alpha=0.1):\n",
    "    return alpha * keras.losses.binary_crossentropy(y_true, y_pred) + (1 - alpha) * keras.losses.binary_crossentropy(soft_labels, y_pred)\n",
    "\n",
    "student_model.compile(optimizer='adam', loss=distillation_loss, metrics=['accuracy'])\n",
    "student_model.fit(X_target_train, y_target_train, epochs=20, validation_data=(X_target_test, y_target_test), verbose=0)\n",
    "\n",
    "# Evaluate student model\n",
    "loss, accuracy = student_model.evaluate(X_target_test, y_target_test, verbose=0)\n",
    "print(f\"Student model accuracy on target domain: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46f1b-fb83-4485-8f4d-99a04bf0a73a",
   "metadata": {},
   "source": [
    "### 500. Implement Logistic Regression Algorithm for Binary Classification with Custom Learning Rate and Regularization\n",
    "\n",
    "Expected Output: \n",
    "Accuracy: xx.xx%\n",
    "\n",
    "Where xx.xx represents the accuracy percentage of the logistic regression model on the test set. Note that due to the randomness of the data generation, the exact accuracy value might vary between runs.\n",
    "\n",
    "Note: The above implementation uses L2 regularization, which can be controlled using the regularization parameter. If you don't want regularization, you can set it to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42679fad-2cb4-4c36-af88-411d5aa088d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, regularization=0.1, epochs=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.reg = regularization\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / num_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # Add regularization term\n",
    "            dw += self.reg * self.weights\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(linear_model)\n",
    "        binary_predictions = [1 if i > 0.5 else 0 for i in predictions]\n",
    "        return binary_predictions\n",
    "\n",
    "# Generate some synthetic data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=10, n_informative=8, n_redundant=1, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(learning_rate=0.1, regularization=0.1, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e0bba-b24e-47c3-954d-65bf4c5539f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
